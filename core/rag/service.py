from .parsing import parse_file
from .processing import chunk_text, embed_texts, rerank_chunks, rewrite_query,chunk_faq
from .vector_store import insert_chunks, search_chunks

async def ingest_file(db, filename: str, file_bytes: bytes, document_id,):
    text = parse_file(filename, file_bytes)
    chunks = chunk_faq(text) 
    embeddings = await embed_texts(chunks)

    await insert_chunks(db, document_id, chunks, embeddings)


async def retrieve_context(db, query: str, limit: int = 3) -> list[str]:
    # 1. –ì–µ–Ω–µ—Ä—É—î–º–æ –≤–∞—Ä—ñ–∞–Ω—Ç–∏ –∑–∞–ø–∏—Ç—ñ–≤
    query_variants = await rewrite_query(query)
    
    # 2. –ü–æ—à—É–∫ –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –≤–∞—Ä—ñ–∞–Ω—Ç—É
    all_results = []
    embedding = await embed_texts(query_variants)
    for embedded_query in embedding:
        chunks = await search_chunks(db, embedded_query, limit=8)
        all_results.append(chunks)
    
    # 3. –†–∞—Ö—É—î–º–æ —Å–∫—ñ–ª—å–∫–∏ —Ä–∞–∑ –∫–æ–∂–µ–Ω —á–∞–Ω–∫ –∑—É—Å—Ç—Ä—ñ—á–∞—î—Ç—å—Å—è
    chunk_counts = {}
    for chunks in all_results:
        for chunk in chunks:
            chunk_counts[chunk] = chunk_counts.get(chunk, 0) + 1
    
    # 4. –í–ò–ë–ò–†–ê–Ñ–ú–û –°–¢–†–ê–¢–ï–ì–Ü–Æ:
    print(chunk_counts)
    # –ê) –ß–∞–Ω–∫–∏, —â–æ –∑—É—Å—Ç—Ä—ñ—á–∞—é—Ç—å—Å—è –≤ ‚â•2 –≤–∞—Ä—ñ–∞–Ω—Ç–∞—Ö
    popular_chunks = [chunk for chunk, count in chunk_counts.items() if count >= 2]
    
    if popular_chunks:
        # ‚úÖ –°—Ç—Ä–∞—Ç–µ–≥—ñ—è 1: –ø—Ä–æ—Å—Ç–æ –ø–æ–≤–µ—Ä—Ç–∞—î–º–æ –ø–æ–ø—É–ª—è—Ä–Ω—ñ —á–∞–Ω–∫–∏
        # –°–æ—Ä—Ç—É—î–º–æ –∑–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—é –≤—Ö–æ–¥–∂–µ–Ω—å (–≤—ñ–¥ –±—ñ–ª—å—à–æ–≥–æ –¥–æ –º–µ–Ω—à–æ–≥–æ)
        popular_chunks_sorted = sorted(
            popular_chunks, 
            key=lambda x: chunk_counts[x], 
            reverse=True
        )
        
        print(f"üéØ –ó–Ω–∞–π–¥–µ–Ω–æ {len(popular_chunks)} –ø–æ–ø—É–ª—è—Ä–Ω–∏—Ö —á–∞–Ω–∫—ñ–≤ (‚â•2 –≤–∞—Ä—ñ–∞–Ω—Ç–∏)")
        print(f"üéØ –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ —Ç–æ–ø-{limit} –∑–∞ –ø–æ–ø—É–ª—è—Ä–Ω—ñ—Å—Ç—é")
        
        return popular_chunks_sorted[:limit]
    
    else:
        # ‚ùå –°—Ç—Ä–∞—Ç–µ–≥—ñ—è 2: –Ω–µ–º–∞—î –ø–æ–ø—É–ª—è—Ä–Ω–∏—Ö —á–∞–Ω–∫—ñ–≤ ‚Üí —é–∑–∞—î–º–æ —Ä–µ—Ä–∞–Ω–∫–µ—Ä
        print("‚ö†Ô∏è  –ü–æ–ø—É–ª—è—Ä–Ω–∏—Ö —á–∞–Ω–∫—ñ–≤ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —Ä–µ—Ä–∞–Ω–∫–µ—Ä")
        
        # –ó–±–∏—Ä–∞—î–º–æ –≤—Å—ñ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ —á–∞–Ω–∫–∏
        all_unique_chunks = list(chunk_counts.keys())
        
        # –†–µ—Ä–∞–Ω–∫—ñ–Ω–≥
        reranked = await rerank_chunks(all_unique_chunks, ' '.join(query_variants))
        
        return reranked[:limit]